{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOaLaTV+nVVT6JX7JB9IoJF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoavdana/ex1_DL/blob/main/ex1_copy2231.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3RC-HpHQ-Hs",
        "outputId": "df7cd424-112a-4b46-ee11-863aa891ae79"
      },
      "source": [
        "!git clone https://github.com/yoavdana/ex1_DL.git"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ex1_DL' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kew0gkAsRDWn"
      },
      "source": [
        "import torch \n",
        "import numpy as np\n",
        "import scipy.stats as si\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "import pandas as pd"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knIQ-N2mRdQH"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_PDI34NMRjw"
      },
      "source": [
        "Data Proccesing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66jPLZBeMMTK"
      },
      "source": [
        "SEQ_LENGTH = 20\n",
        "BATCH_SIZE = 64\n",
        "MAPPING = {'A': 0, 'R': 1, 'N': 2, 'D': 3, 'C': 4, 'E': 5, 'Q': 6, 'G': 7, 'H': 8, 'I': 9, 'L': 10, 'K': 11,\n",
        "              'M': 12, 'F': 13, 'P': 14, 'S': 15, 'T': 16, 'W': 17, 'Y': 18, 'V': 19}\n",
        "\n",
        "\n",
        "def data_to_input(sequence, pos_or_neg):\n",
        "    map=np.zeros((9, 20))\n",
        "    for i, seq in enumerate(sequence):\n",
        "        map[i,MAPPING[seq]]+=1\n",
        "    map = map.flatten()\n",
        "    return np.concatenate([map, np.array([pos_or_neg])])\n",
        "\n",
        "def read_data(filename, pos_or_neg):\n",
        "    file = open(filename, 'r')\n",
        "    lines=file.readlines()\n",
        "    data = np.zeros((len(lines), 181))\n",
        "    for i, line in enumerate(lines):\n",
        "        input = data_to_input(line.replace('\\n', ''), pos_or_neg)\n",
        "        data[i] = input\n",
        "    return data\n",
        "\n",
        "# def bootstrap(DATA,size,NUMBER_OF_BATCHS):\n",
        "\n",
        "#     new_DATA=np.zeros((size,181))\n",
        "#     N=DATA.shape[0]\n",
        "#     batch_size=N//NUMBER_OF_BATCHS\n",
        "#     for i in range(NUMBER_OF_BATCHS):\n",
        "\n",
        "#         random = np.random.randint(batch_size*i,batch_size*(i+1), size=size//NUMBER_OF_BATCHS)\n",
        "#         new_DATA[((size//NUMBER_OF_BATCHS)*i):(size//NUMBER_OF_BATCHS)*(i+1), :] = DATA[random, :]\n",
        "#     return new_DATA\n",
        "\n",
        "\n",
        "def bootstrap(data,size,NUMBER_OF_BATCHS):\n",
        "\n",
        "    N=data.shape[0]\n",
        "    batch_size=N//NUMBER_OF_BATCHS\n",
        "    for i in range(NUMBER_OF_BATCHS):\n",
        "        random = np.random.randint(batch_size*i,batch_size*(i+1), size=size//NUMBER_OF_BATCHS)\n",
        "        data =np.vstack([DATA,DATA[random, :]])\n",
        "    return data\n",
        "\n",
        "\n",
        "def data_pre_pros(filename_pos,filename_neg):\n",
        "\n",
        "    neg_data=read_data(filename_neg, 0)\n",
        "    pos_data=read_data(filename_pos, 1)\n",
        "    \n",
        "    neg_data_train = neg_data[:int(len(neg_data)*0.9)]\n",
        "    neg_data_test = neg_data[int(len(neg_data)*0.9):]\n",
        "    pos_data_train = pos_data[:int(len(pos_data)*0.9)]\n",
        "    pos_data_test = pos_data[int(len(pos_data)*0.9):]\n",
        "    #pos_data_train = bootstrap(pos_data_train, int(BOOTSTRAP_SIZE*0.9), int(NUMBER_OF_BATCHS*0.9))\n",
        "    #pos_data_test = bootstrap(pos_data_test, int(BOOTSTRAP_SIZE*0.1), int(NUMBER_OF_BATCHS*0.1))\n",
        "\n",
        "    final_data_train = np.concatenate([neg_data_train, pos_data_train])\n",
        "    final_data_test = np.concatenate([neg_data_test, pos_data_test])\n",
        "    return final_data_train, final_data_test\n",
        "\n",
        "\n",
        "def shuffle_data(data_Xy):\n",
        "    np.random.shuffle(data_Xy)\n",
        "    return data_Xy[:,:180],data_Xy[:,-1]\n",
        "\n",
        "\n",
        "def spike_seq(filename):\n",
        "    with open(filename) as f:\n",
        "        lines = f.readlines()[0]\n",
        "        print(lines)\n",
        "        predeict=list()\n",
        "\n",
        "        if len(lines) == 9:\n",
        "            map = np.zeros((9, 20))\n",
        "            for i, seq in enumerate(lines):\n",
        "                map[i, MAPPING[seq]] += 1\n",
        "            map = map.flatten()\n",
        "            predeict.append(map)\n",
        "        else:\n",
        "            for i in range(len(lines)-9):\n",
        "                map = np.zeros((9, 20))\n",
        "                for i, seq in enumerate(lines[i:i+9]):\n",
        "                    map[i, MAPPING[seq]] += 1\n",
        "                map = map.flatten()\n",
        "                predeict.append(map)\n",
        "        \n",
        "        return np.array(predeict)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYNbU_SaRgzZ"
      },
      "source": [
        "filename_pos='/content/ex1_DL/resorces/pos_A0201.txt'\n",
        "filename_neg='/content/ex1_DL/resorces/neg_A0201.txt'\n",
        "\n",
        "train_set, test_set=data_pre_pros(filename_pos,filename_neg)\n",
        "train_x, train_y = train_set[:,:180], train_set[:,-1]\n",
        "test_x, test_y = test_set[:,:180], test_set[:,-1]\n",
        "\n",
        "train_target = torch.from_numpy(train_y.astype(np.int64))\n",
        "train = torch.from_numpy(train_x.astype(np.float32)) \n",
        "train_tensor = torch.utils.data.TensorDataset(train, train_target) \n",
        "train_dataloader = torch.utils.data.DataLoader(dataset = train_tensor, batch_size = BATCH_SIZE, shuffle = True)\n",
        "\n",
        "test_target = torch.from_numpy(test_y.astype(np.int64))\n",
        "test = torch.from_numpy(test_x.astype(np.float32)) \n",
        "test_tensor = torch.utils.data.TensorDataset(test, test_target) \n",
        "test_dataloader = torch.utils.data.DataLoader(dataset = test_tensor, batch_size = BATCH_SIZE, shuffle = True)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkOKJ3pkTRut"
      },
      "source": [
        "# Evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08W0jQWQTnvo"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def calculate_accuracy(y_pred, y):\n",
        "    top_pred = y_pred.argmax(1, keepdim = True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc\n",
        "\n",
        "\n",
        "def calculate_accuracy(y_pred, y):\n",
        "    top_pred = y_pred.argmax(1, keepdim = True)\n",
        "    f1 = f1_score(y_pred,y)\n",
        "    return f1\n",
        "    \n",
        "\n",
        "def f1_loss(y_true, y_pred, is_training=False):\n",
        "    assert y_true.ndim == 1\n",
        "    assert y_pred.ndim == 1 or y_pred.ndim == 2\n",
        "   \n",
        "    if y_pred.ndim == 2:\n",
        "        y_pred = y_pred.argmax(dim=1)\n",
        "       \n",
        "   \n",
        "    tp = (y_true * y_pred).sum().to(torch.float32)\n",
        "    tn = ((1 - y_true) * (1 - y_pred)).sum().to(torch.float32)\n",
        "    fp = ((1 - y_true) * y_pred).sum().to(torch.float32)\n",
        "    fn = (y_true * (1 - y_pred)).sum().to(torch.float32)\n",
        "   \n",
        "    epsilon = 1e-7\n",
        "   \n",
        "    precision = tp / (tp + fp + epsilon)\n",
        "    recall = tp / (tp + fn + epsilon)\n",
        "   \n",
        "    f1 = 2* (precision*recall) / (precision + recall + epsilon)\n",
        "    f1.requires_grad = is_training\n",
        "    return f1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhkcZrZYU9jQ"
      },
      "source": [
        "## Network architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU3l7iJlVG6k"
      },
      "source": [
        "# Network parameters\n",
        "INPUT=180\n",
        "INPUT_1=128\n",
        "INPUT_2=64\n",
        "INPUT_3=32\n",
        "INPUT_4=32\n",
        "INPUT_5=16\n",
        "INPUT_6=8\n",
        "INPUT_7=4\n",
        "OUTPUT=2\n",
        "P_DROPOUT=0.25\n",
        "P_DROPOUT_2=0.15\n",
        "\n",
        "LEARNNING_RATE=0.0015\n",
        "\n",
        "BOOTSTRAP_SIZE=15000\n",
        "NUMBER_OF_BATCHS=150\n",
        "\n",
        "EPOCHS = 30"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9TzVlOwVcaI"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        self.input_fc = nn.Linear(INPUT, INPUT_1)\n",
        "        \n",
        "        self.hidden_1_fc = nn.Linear(INPUT_1, INPUT_2)\n",
        "        \n",
        "        self.hidden_2_fc = nn.Linear(INPUT_2, INPUT_3)\n",
        "\n",
        "        self.hidden_3_fc = nn.Linear(INPUT_3, INPUT_4)\n",
        "\n",
        "        self.hidden_4_fc = nn.Linear(INPUT_4, INPUT_5)\n",
        "\n",
        "        self.hidden_5_fc = nn.Linear(INPUT_5, INPUT_6)\n",
        "        \n",
        "        self.hidden_6_fc = nn.Linear(INPUT_6, INPUT_7)\n",
        "\n",
        "        self.output_fc = nn.Linear(INPUT_7, OUTPUT)\n",
        "\n",
        "        self.dropout = nn.Dropout(P_DROPOUT)\n",
        "        # self.dropout_2 = nn.Dropout(P_DROPOUT_2) \n",
        "        \n",
        "        self.batch_norm_1 = nn.BatchNorm1d(INPUT_1)\n",
        "        self.batch_norm_2 = nn.BatchNorm1d(INPUT_2)\n",
        "        self.batch_norm_3 = nn.BatchNorm1d(INPUT_3)\n",
        "        self.batch_norm_4 = nn.BatchNorm1d(INPUT_4)\n",
        "        self.batch_norm_5 = nn.BatchNorm1d(INPUT_5)\n",
        "        self.batch_norm_6 = nn.BatchNorm1d(INPUT_6)\n",
        "        self.batch_norm_7 = nn.BatchNorm1d(INPUT_7)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        h_1 = F.relu(self.input_fc(x))\n",
        "\n",
        "        # h_1=self.batch_norm_1(h_1)\n",
        "        \n",
        "        # h_1=self.dropout(h_1)\n",
        "        \n",
        "        h_2 = F.relu(self.hidden_1_fc(h_1))\n",
        "        \n",
        "        # h_2=self.batch_norm_2(h_2)\n",
        "        \n",
        "        h_2=self.dropout(h_2)\n",
        "        \n",
        "        h_3 = F.relu(self.hidden_2_fc(h_2))\n",
        "        \n",
        "        # h_3=self.batch_norm_3(h_3)\n",
        "        \n",
        "        # h_3=self.dropout(h_3)\n",
        "\n",
        "        h_4 = F.relu(self.hidden_3_fc(h_3))\n",
        "        \n",
        "        # h_4=self.batch_norm_4(h_4)\n",
        "        \n",
        "        h_4=self.dropout(h_4)\n",
        "\n",
        "        h_5 = F.relu(self.hidden_4_fc(h_4))\n",
        "        \n",
        "        # h_5=self.batch_norm_5(h_5)\n",
        "        \n",
        "        # h_5=self.dropout(h_5)\n",
        "\n",
        "        h_6 = F.relu(self.hidden_5_fc(h_5))\n",
        "        \n",
        "        # h_6=self.batch_norm_6(h_6)\n",
        "        \n",
        "        # h_6=self.dropout(h_6)\n",
        "\n",
        "        h_7 = F.relu(self.hidden_6_fc(h_6))\n",
        "        \n",
        "        # h_7=self.batch_norm_7(h_7)\n",
        "        \n",
        "        # h_7=self.dropout(h_7)\n",
        "        \n",
        "        y_pred = self.output_fc(h_7)\n",
        "        \n",
        "        return y_pred, h_7\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Network().to(device)\n",
        "optimizer=optim.Adam(model.parameters(), lr=LEARNNING_RATE)\n",
        "weights = [train_set.shape[0]/(2*np.sum(train_set[:, -1])), np.sum(train_set[:, -1])/(2*(train_set.shape[0]-np.sum(train_set[:, -1])))] #as class distribution\n",
        "weights.reverse()\n",
        "class_weights = torch.FloatTensor(weights).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mb8kMOWPiG_"
      },
      "source": [
        "# Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uFUj0MVPgoO",
        "outputId": "5b3faf6e-7259-43bb-ac42-82cf0538d698"
      },
      "source": [
        "start_time=time()\n",
        "\n",
        "for epoch in range(20):\n",
        "    running_loss=0.0\n",
        "    pbar=tqdm(iterable=train_dataloader)\n",
        "    for i,batch in enumerate(pbar):\n",
        "      batch=[item.to(device) for  item in batch]\n",
        "      sequences, labels=batch\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "      # forward \n",
        "      outputs, _ = model(sequences)\n",
        "      #calculate the loss between the target and the actuals\n",
        "      loss= criterion(input=outputs, target=labels)\n",
        "      #Gradient calculation uisng backward pass\n",
        "      loss.backward()\n",
        "      # update the weights\n",
        "      optimizer.step()\n",
        "      running_loss+=loss.item()\n",
        "      pbar.set_postfix(loss=running_loss/(i+1))\n",
        "    pbar.close()\n",
        "    print('epoch %d -Loss %.3f' % (epoch +1,running_loss/(len(train_tensor)/BATCH_SIZE)))      \n",
        "    running_loss = 0.0\n",
        "\n",
        "print(\"Time for training using PyTorch %f\" %(time()-start_time))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 387/387 [00:02<00:00, 131.85it/s, loss=0.018]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 -Loss 0.018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 387/387 [00:02<00:00, 133.56it/s, loss=0.0181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 -Loss 0.018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 387/387 [00:02<00:00, 138.24it/s, loss=0.0186]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 -Loss 0.019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 387/387 [00:02<00:00, 133.21it/s, loss=0.0151]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 -Loss 0.015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 387/387 [00:03<00:00, 127.51it/s, loss=0.0191]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 -Loss 0.019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 387/387 [00:03<00:00, 128.15it/s, loss=0.016]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6 -Loss 0.016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 387/387 [00:02<00:00, 129.59it/s, loss=0.0135]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7 -Loss 0.013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 387/387 [00:03<00:00, 128.29it/s, loss=0.0144]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8 -Loss 0.014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 387/387 [00:02<00:00, 131.23it/s, loss=0.0109]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9 -Loss 0.011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 387/387 [00:02<00:00, 133.31it/s, loss=0.00955]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 10 -Loss 0.010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 387/387 [00:02<00:00, 133.27it/s, loss=0.00723]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 11 -Loss 0.007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 387/387 [00:02<00:00, 132.78it/s, loss=0.0195]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 12 -Loss 0.019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 387/387 [00:02<00:00, 129.47it/s, loss=0.0179]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 13 -Loss 0.018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 387/387 [00:02<00:00, 131.40it/s, loss=0.0105]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 14 -Loss 0.011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 387/387 [00:02<00:00, 131.14it/s, loss=0.0142]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 15 -Loss 0.014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 387/387 [00:02<00:00, 132.84it/s, loss=0.012]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 16 -Loss 0.012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 387/387 [00:03<00:00, 123.31it/s, loss=0.0142]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 17 -Loss 0.014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 387/387 [00:03<00:00, 122.04it/s, loss=0.00648]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 18 -Loss 0.006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 387/387 [00:03<00:00, 124.42it/s, loss=0.0094]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 19 -Loss 0.009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 387/387 [00:02<00:00, 131.19it/s, loss=0.00852]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 20 -Loss 0.009\n",
            "Time for training using PyTorch 59.590492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34cbmGnjpMtR"
      },
      "source": [
        "def train_model(model, train_dataloader, optimizer, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train()\n",
        "\n",
        "    for i,batch in enumerate(train_dataloader):\n",
        "        batch=[item.to(device) for item in batch]\n",
        "        sequences, labels=batch\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "      \n",
        "        # forward \n",
        "        outputs, _ = model(sequences)\n",
        "        #calculate the loss between the target and the actuals\n",
        "        loss= criterion(input=outputs, target=labels)\n",
        "        #Gradient calculation uisng backward pass\n",
        "        acc=f1_loss(labels, outputs, is_training=False)\n",
        "        loss.backward()\n",
        "        # update the weights\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(train_dataloader), epoch_acc / len(train_dataloader)\n",
        "\n",
        "\n",
        "def evaluate(model, train_dataloader, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "\n",
        "    for i,batch in enumerate(train_dataloader):\n",
        "        batch=[item.to(device) for item in batch]\n",
        "        sequences, labels=batch\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "      \n",
        "        # forward \n",
        "        outputs, _ = model(sequences)\n",
        "        #calculate the loss between the target and the actuals\n",
        "        loss= criterion(input=outputs, target=labels)\n",
        "        #Gradient calculation uisng backward pass\n",
        "        acc=f1_loss(labels, outputs, is_training=False)\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(train_dataloader), epoch_acc / len(train_dataloader)\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D7OQ_DBFrHs7",
        "outputId": "ed29a0e8-a420-407e-88f0-1790d3bf2644"
      },
      "source": [
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "train_per_ep=[]\n",
        "test_per_ep=[]\n",
        "test_acc = 0\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss, train_acc = train_model(model, train_dataloader, optimizer, criterion, device)\n",
        "    test_loss, test_acc = evaluate(model, train_dataloader,criterion, device)\n",
        "    train_per_ep.append(train_loss)\n",
        "    test_per_ep.append(test_loss)\n",
        "    \n",
        "    print(f'Epoch: {epoch + 1:02}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
        "    print(f'Epoch: {epoch + 1:02}')\n",
        "    print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc * 100:.2f}%')\n",
        "\n",
        "train_per_ep=np.array(train_per_ep)\n",
        "test_per_ep=np.array(test_per_ep)\n",
        "epocs=np.arange(1,EPOCHS+1)\n",
        "print(np.mean(np.abs(np.array(train_per_ep) - np.array(test_per_ep))))\n",
        "plt.figure()\n",
        "plt.plot(epocs,train_per_ep)\n",
        "plt.plot(epocs,test_per_ep)\n",
        "plt.legend(['train loss','test loss'])\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 35,838 trainable parameters\n",
            "Epoch: 01\n",
            "\tTrain Loss: 0.215 | Train Acc: 36.59%\n",
            "Epoch: 01\n",
            "\tTest Loss: 0.126 | Test Acc: 48.90%\n",
            "Epoch: 02\n",
            "\tTrain Loss: 0.129 | Train Acc: 47.76%\n",
            "Epoch: 02\n",
            "\tTest Loss: 0.103 | Test Acc: 50.36%\n",
            "Epoch: 03\n",
            "\tTrain Loss: 0.111 | Train Acc: 50.12%\n",
            "Epoch: 03\n",
            "\tTest Loss: 0.097 | Test Acc: 49.23%\n",
            "Epoch: 04\n",
            "\tTrain Loss: 0.101 | Train Acc: 52.88%\n",
            "Epoch: 04\n",
            "\tTest Loss: 0.090 | Test Acc: 51.63%\n",
            "Epoch: 05\n",
            "\tTrain Loss: 0.092 | Train Acc: 54.89%\n",
            "Epoch: 05\n",
            "\tTest Loss: 0.082 | Test Acc: 54.68%\n",
            "Epoch: 06\n",
            "\tTrain Loss: 0.078 | Train Acc: 59.47%\n",
            "Epoch: 06\n",
            "\tTest Loss: 0.074 | Test Acc: 57.67%\n",
            "Epoch: 07\n",
            "\tTrain Loss: 0.078 | Train Acc: 59.62%\n",
            "Epoch: 07\n",
            "\tTest Loss: 0.070 | Test Acc: 58.78%\n",
            "Epoch: 08\n",
            "\tTrain Loss: 0.068 | Train Acc: 63.12%\n",
            "Epoch: 08\n",
            "\tTest Loss: 0.075 | Test Acc: 54.71%\n",
            "Epoch: 09\n",
            "\tTrain Loss: 0.067 | Train Acc: 63.58%\n",
            "Epoch: 09\n",
            "\tTest Loss: 0.062 | Test Acc: 59.61%\n",
            "Epoch: 10\n",
            "\tTrain Loss: 0.058 | Train Acc: 68.06%\n",
            "Epoch: 10\n",
            "\tTest Loss: 0.054 | Test Acc: 64.16%\n",
            "Epoch: 11\n",
            "\tTrain Loss: 0.052 | Train Acc: 69.92%\n",
            "Epoch: 11\n",
            "\tTest Loss: 0.047 | Test Acc: 75.71%\n",
            "Epoch: 12\n",
            "\tTrain Loss: 0.057 | Train Acc: 68.87%\n",
            "Epoch: 12\n",
            "\tTest Loss: 0.063 | Test Acc: 59.09%\n",
            "Epoch: 13\n",
            "\tTrain Loss: 0.048 | Train Acc: 72.51%\n",
            "Epoch: 13\n",
            "\tTest Loss: 0.041 | Test Acc: 76.92%\n",
            "Epoch: 14\n",
            "\tTrain Loss: 0.047 | Train Acc: 74.12%\n",
            "Epoch: 14\n",
            "\tTest Loss: 0.041 | Test Acc: 73.59%\n",
            "Epoch: 15\n",
            "\tTrain Loss: 0.042 | Train Acc: 76.01%\n",
            "Epoch: 15\n",
            "\tTest Loss: 0.037 | Test Acc: 75.09%\n",
            "Epoch: 16\n",
            "\tTrain Loss: 0.040 | Train Acc: 75.31%\n",
            "Epoch: 16\n",
            "\tTest Loss: 0.033 | Test Acc: 78.00%\n",
            "Epoch: 17\n",
            "\tTrain Loss: 0.036 | Train Acc: 78.35%\n",
            "Epoch: 17\n",
            "\tTest Loss: 0.034 | Test Acc: 75.29%\n",
            "Epoch: 18\n",
            "\tTrain Loss: 0.044 | Train Acc: 75.42%\n",
            "Epoch: 18\n",
            "\tTest Loss: 0.034 | Test Acc: 76.01%\n",
            "Epoch: 19\n",
            "\tTrain Loss: 0.033 | Train Acc: 79.88%\n",
            "Epoch: 19\n",
            "\tTest Loss: 0.024 | Test Acc: 82.92%\n",
            "Epoch: 20\n",
            "\tTrain Loss: 0.031 | Train Acc: 81.64%\n",
            "Epoch: 20\n",
            "\tTest Loss: 0.036 | Test Acc: 73.00%\n",
            "Epoch: 21\n",
            "\tTrain Loss: 0.032 | Train Acc: 80.28%\n",
            "Epoch: 21\n",
            "\tTest Loss: 0.025 | Test Acc: 81.80%\n",
            "Epoch: 22\n",
            "\tTrain Loss: 0.032 | Train Acc: 79.95%\n",
            "Epoch: 22\n",
            "\tTest Loss: 0.025 | Test Acc: 86.66%\n",
            "Epoch: 23\n",
            "\tTrain Loss: 0.037 | Train Acc: 77.00%\n",
            "Epoch: 23\n",
            "\tTest Loss: 0.024 | Test Acc: 80.95%\n",
            "Epoch: 24\n",
            "\tTrain Loss: 0.028 | Train Acc: 81.98%\n",
            "Epoch: 24\n",
            "\tTest Loss: 0.022 | Test Acc: 83.46%\n",
            "Epoch: 25\n",
            "\tTrain Loss: 0.025 | Train Acc: 84.50%\n",
            "Epoch: 25\n",
            "\tTest Loss: 0.026 | Test Acc: 81.18%\n",
            "Epoch: 26\n",
            "\tTrain Loss: 0.029 | Train Acc: 83.49%\n",
            "Epoch: 26\n",
            "\tTest Loss: 0.018 | Test Acc: 85.21%\n",
            "Epoch: 27\n",
            "\tTrain Loss: 0.019 | Train Acc: 87.78%\n",
            "Epoch: 27\n",
            "\tTest Loss: 0.016 | Test Acc: 89.10%\n",
            "Epoch: 28\n",
            "\tTrain Loss: 0.018 | Train Acc: 88.24%\n",
            "Epoch: 28\n",
            "\tTest Loss: 0.016 | Test Acc: 87.11%\n",
            "Epoch: 29\n",
            "\tTrain Loss: 0.021 | Train Acc: 87.02%\n",
            "Epoch: 29\n",
            "\tTest Loss: 0.018 | Test Acc: 84.29%\n",
            "Epoch: 30\n",
            "\tTrain Loss: 0.024 | Train Acc: 85.17%\n",
            "Epoch: 30\n",
            "\tTest Loss: 0.018 | Test Acc: 85.02%\n",
            "0.009980879440032446\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}