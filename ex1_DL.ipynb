{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex1_DL.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/yoavdana/ex1_DL/blob/main/ex1_DL.ipynb",
      "authorship_tag": "ABX9TyOeDAIGSVILzMBvLZO3Tmvs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoavdana/ex1_DL/blob/main/ex1_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tNlOLLOv5q8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c23f2ef0-c88b-4230-a4ba-0245d0c6f8c5"
      },
      "source": [
        "!git clone https://github.com/yoavdana/ex1_DL.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ex1_DL' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9c1XQ2OEx8t"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import scipy.stats as si\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "INPUT_DIM = 9 * 20\n",
        "OUTPUT_DIM = 2\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5V0o627FZyo"
      },
      "source": [
        "SEQ_LENGTH=20\n",
        "BOOTSTRAP_SIZE=24000\n",
        "NUMBER_OF_BATCHS=5\n",
        "\n",
        "\n",
        "\n",
        "def data_to_input(sequence, pos_or_neg):\n",
        "    mapping = {'A': 0, 'R': 1, 'N': 2, 'D': 3, 'C': 4, 'E': 5, 'Q': 6, 'G': 7, 'H': 8, 'I': 9, 'L': 10, 'K': 11,\n",
        "               'M': 12, 'F': 13, 'P': 14, 'S': 15, 'T': 16, 'W': 17, 'Y': 18, 'V': 19}\n",
        "    map=np.zeros((9, 20))\n",
        "    for i, seq in enumerate(sequence):\n",
        "        map[i,mapping[seq]]+=1\n",
        "    map = map.flatten()\n",
        "    return np.concatenate([map, np.array([pos_or_neg])])\n",
        "\n",
        "\n",
        "def Read_Data(filename, pos_or_neg):\n",
        "    file = open(filename, 'r')\n",
        "    lines=file.readlines()\n",
        "    if pos_or_neg==1:\n",
        "        DATA=np.zeros((len(lines), 181))\n",
        "        for i, line in enumerate(lines):\n",
        "            input = data_to_input(line.replace('\\n', ''), pos_or_neg)\n",
        "            DATA[i] = input\n",
        "        DATA=bootstrap(DATA, BOOTSTRAP_SIZE, NUMBER_OF_BATCHS)\n",
        "    else:\n",
        "        DATA = np.zeros((len(lines), 181))\n",
        "        for i, line in enumerate(lines):\n",
        "            input = data_to_input(line.replace('\\n', ''), pos_or_neg)\n",
        "            DATA[i] = input\n",
        "    return DATA\n",
        "\n",
        "\n",
        "def bootstrap(DATA,size,NUMBER_OF_BATCHS):\n",
        "\n",
        "    new_DATA=np.zeros((size,181))\n",
        "    N=DATA.shape[0]\n",
        "    batch_size=N//NUMBER_OF_BATCHS\n",
        "    for i in range(NUMBER_OF_BATCHS):\n",
        "\n",
        "        random = np.random.randint(batch_size*i,batch_size*(i+1), size=size//NUMBER_OF_BATCHS)\n",
        "        new_DATA[((size//NUMBER_OF_BATCHS)*i):(size//NUMBER_OF_BATCHS)*(i+1), :] = DATA[random, :]\n",
        "    return new_DATA\n",
        "\n",
        "\n",
        "def DATA_pre_pros(filename_pos,filename_neg):\n",
        "\n",
        "    neg_data=Read_Data(filename_neg, 0)\n",
        "    pos_data=Read_Data(filename_pos, 1)\n",
        "    final_data = np.concatenate([neg_data, pos_data])\n",
        "    np.random.shuffle(final_data)\n",
        "    train_set = final_data[:int(len(final_data)*0.9)]\n",
        "    test_set = final_data[int(len(final_data)*0.9):]\n",
        "    return train_set, test_set\n",
        "\n",
        "\n",
        "\n",
        "def shuffle_data(data_Xy):\n",
        "    np.random.shuffle(data_Xy)\n",
        "    return data_Xy[:,:180],data_Xy[:,-1]\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HutCXePsE9KO"
      },
      "source": [
        "INPUT_1=100\n",
        "INPUT_2=50\n",
        "INPUT_3=10\n",
        "P_DROPOUT=0.25\n",
        "\n",
        "\n",
        "class NetWork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_fc = nn.Linear(input_dim, INPUT_1)\n",
        "        \n",
        "        self.hidden_1_fc = nn.Linear(INPUT_1, INPUT_2)\n",
        "        \n",
        "        self.hidden_2_fc = nn.Linear(INPUT_2, INPUT_3)\n",
        "        \n",
        "        self.output_fc = nn.Linear(INPUT_3, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(P_DROPOUT)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "   \n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "\n",
        "        h_1 = F.relu(self.input_fc(x))\n",
        "\n",
        "        h_1=self.dropout(h_1)\n",
        "       \n",
        "\n",
        "        h_2 = F.relu(self.hidden_1_fc(h_1))\n",
        "\n",
        "\n",
        "        h_3 = F.relu(self.hidden_2_fc(h_2))\n",
        "\n",
        "\n",
        "        y_pred = self.output_fc(h_3)\n",
        "\n",
        "       \n",
        "        \n",
        "        return y_pred, h_2\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1jysnYBFurA"
      },
      "source": [
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def calculate_accuracy(y_pred, y):\n",
        "    top_pred = y_pred.argmax(1, keepdim = True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc\n",
        "\n",
        "\n",
        "def train(model, iterator_x, iterator_y, optimizer, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i, x in enumerate(iterator_x):\n",
        "        x = x.to(device)\n",
        "        y = iterator_y[i].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred, _ = model(x)\n",
        "\n",
        "        loss = criterion(y_pred, y)\n",
        "\n",
        "        acc = calculate_accuracy(y_pred, y)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator_x), epoch_acc / len(iterator_x)\n",
        "\n",
        "\n",
        "def evaluate(model, iterator_x, iterator_y, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for i, x in enumerate(iterator_x):\n",
        "        x = x.to(device)\n",
        "        y = iterator_y[i].to(device)\n",
        "\n",
        "        y_pred, _ = model(x)\n",
        "\n",
        "        loss = criterion(y_pred, y)\n",
        "\n",
        "        acc = calculate_accuracy(y_pred, y)\n",
        "\n",
        " \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator_x), epoch_acc / len(iterator_x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNHufHg2Gyz5"
      },
      "source": [
        "filename_pos='/content/ex1_DL/resorces/pos_A0201.txt'\n",
        "filename_neg='/content/ex1_DL/resorces/neg_A0201.txt'\n",
        "\n",
        "train_set, test_set=DATA_pre_pros(filename_pos,filename_neg)\n",
        "\n",
        "# LEARNNING_RATE=0.00015\n",
        "\n",
        "def main():\n",
        "    model = NetWork(INPUT_DIM, 2)\n",
        "    print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "    optimizer = optim.Adam(model.parameters(),lr=LEARNNING_RATE)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "    criterion = criterion.to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    EPOCHS = 50\n",
        "\n",
        "    best_valid_loss = float('inf')\n",
        "    train_per_ep=[]\n",
        "    test_per_ep=[]\n",
        "    test_acc = 0\n",
        "    for epoch in range(EPOCHS):\n",
        "\n",
        "\n",
        "        train_x,train_y=shuffle_data(train_set)\n",
        "        train_iterator_x = torch.from_numpy(train_x.astype('float32')).split(64)\n",
        "        train_iterator_y = torch.from_numpy(train_y.astype('int64')).split(64)\n",
        "\n",
        "        test_x,test_y=shuffle_data(test_set)\n",
        "        test_iterator_x = torch.from_numpy(test_x.astype('float32')).split(64)\n",
        "        test_iterator_y = torch.from_numpy(test_y.astype('int64')).split(64)\n",
        "\n",
        "        train_loss, train_acc = train(model, train_iterator_x, train_iterator_y, optimizer, criterion, device)\n",
        "\n",
        "        test_loss, test_acc = evaluate(model, test_iterator_x, test_iterator_y,criterion, device)\n",
        "        train_per_ep.append(train_loss)\n",
        "        test_per_ep.append(test_loss)\n",
        "        \n",
        "        print(f'Epoch: {epoch + 1:02}')\n",
        "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
        "        print(f'Epoch: {epoch + 1:02}')\n",
        "        print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc * 100:.2f}%')\n",
        "\n",
        "    train_per_ep=np.array(train_per_ep)\n",
        "    test_per_ep=np.array(test_per_ep)\n",
        "    epocs=np.arange(1,EPOCHS+1)\n",
        "    # plt.figure()\n",
        "    # plt.plot(epocs,train_per_ep)\n",
        "    # plt.plot(epocs,test_per_ep)\n",
        "    # plt.legend(['train loss','test loss'])\n",
        "    # plt.show()\n",
        "    return test_acc, np.mean(np.abs(np.array(train_per_ep) - np.array(test_per_ep)))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkTUKuGfTuIE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "55ee4587-8012-436c-9cae-8c3ac2b234a6"
      },
      "source": [
        "learning_rate = np.linspace(0.0001, 0.001, num=10)\n",
        "input_1 = [70, 100, 130, 150]\n",
        "input_2 = [30, 40, 50, 60]\n",
        "input_3 = [10, 15, 20, 25]\n",
        "p = [0.2, 0.25, 0.35, 0.42, 0.5] \n",
        "acc = list()\n",
        "overfit=list()\n",
        "all=np.load('/content/drive/MyDrive/Colab Notebooks/opt.npy',allow_pickle=True)\n",
        "i=0\n",
        "for rate in learning_rate:\n",
        "  for input_1_ in input_1:\n",
        "    for input_2_ in input_2:\n",
        "      for input_3_ in input_3:\n",
        "        for p_ in p:\n",
        "            LEARNNING_RATE = rate\n",
        "            INPUT_1 = input_1_\n",
        "            INPUT_2 = input_2_\n",
        "            INPUT_3 = input_3_\n",
        "            P_DROPOUT = p_ \n",
        "\n",
        "            if any((np.array([INPUT_1,INPUT_2,INPUT_3,P_DROPOUT,LEARNNING_RATE])==all[:,0:-2]).all(1)):\n",
        "              print(i)\n",
        "              i+=1\n",
        "              continue\n",
        "            else:  \n",
        "              ac,of = main()\n",
        "              acc.append(ac)\n",
        "              overfit.append(of)\n",
        "              params=np.array([INPUT_1,INPUT_2,INPUT_3,P_DROPOUT,LEARNNING_RATE, ac, of])\n",
        "              all=np.vstack([all, params])\n",
        "              np.save('/content/drive/MyDrive/Colab Notebooks/opt.npy',all)\n",
        "          \n",
        "\n",
        "        \n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "The model has 15,627 trainable parameters\n",
            "Epoch: 01\n",
            "\tTrain Loss: 0.402 | Train Acc: 81.35%\n",
            "Epoch: 01\n",
            "\tTest Loss: 0.249 | Test Acc: 89.92%\n",
            "Epoch: 02\n",
            "\tTrain Loss: 0.249 | Train Acc: 90.25%\n",
            "Epoch: 02\n",
            "\tTest Loss: 0.235 | Test Acc: 90.26%\n",
            "Epoch: 03\n",
            "\tTrain Loss: 0.236 | Train Acc: 90.89%\n",
            "Epoch: 03\n",
            "\tTest Loss: 0.225 | Test Acc: 91.18%\n",
            "Epoch: 04\n",
            "\tTrain Loss: 0.224 | Train Acc: 91.41%\n",
            "Epoch: 04\n",
            "\tTest Loss: 0.215 | Test Acc: 91.77%\n",
            "Epoch: 05\n",
            "\tTrain Loss: 0.209 | Train Acc: 92.21%\n",
            "Epoch: 05\n",
            "\tTest Loss: 0.203 | Test Acc: 92.65%\n",
            "Epoch: 06\n",
            "\tTrain Loss: 0.199 | Train Acc: 92.67%\n",
            "Epoch: 06\n",
            "\tTest Loss: 0.194 | Test Acc: 93.26%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0eb7eb4980f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m               \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m               \u001b[0mac\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m               \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m               \u001b[0moverfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-2f6b6c145ea8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mtrain_iterator_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mtrain_iterator_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-4c912edc4b0b>\u001b[0m in \u001b[0;36mshuffle_data\u001b[0;34m(data_Xy)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshuffle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_Xy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_Xy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata_Xy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_Xy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZWo5iKwKtfD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "179a0c34-5644-40b4-f268-6737d29d3d00"
      },
      "source": [
        "a=np.load('/content/drive/MyDrive/Colab Notebooks/opt.npy')\n",
        "print(np.array([7.0e+01,3.0e+01,1.0e+01,2.0e-01,1.0e-04]) in a[:,0:-2])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    }
  ]
}