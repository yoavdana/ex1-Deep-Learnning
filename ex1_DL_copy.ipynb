{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex1_DL.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/yoavdana/ex1_DL/blob/main/ex1_DL.ipynb",
      "authorship_tag": "ABX9TyN8g3T9f0S4KIt/2DyWcpYo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoavdana/ex1_DL/blob/main/ex1_DL_copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tNlOLLOv5q8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bce40f67-7f97-4520-db81-ecd8f5a2913f"
      },
      "source": [
        "!git clone https://github.com/yoavdana/ex1_DL.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ex1_DL'...\n",
            "remote: Enumerating objects: 100, done.\u001b[K\n",
            "remote: Counting objects: 100% (100/100), done.\u001b[K\n",
            "remote: Compressing objects: 100% (84/84), done.\u001b[K\n",
            "remote: Total 100 (delta 35), reused 48 (delta 9), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (100/100), 59.20 MiB | 29.77 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9c1XQ2OEx8t"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import scipy.stats as si\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "INPUT_DIM = 9 * 20\n",
        "OUTPUT_DIM = 2\n",
        "\n"
      ],
      "execution_count": 306,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5V0o627FZyo"
      },
      "source": [
        "SEQ_LENGTH=20\n",
        "BOOTSTRAP_SIZE=13000\n",
        "NUMBER_OF_BATCHS=200\n",
        "\n",
        "class DataProccesing(data.Dataset):\n",
        "\n",
        "\n",
        "    def data_to_input(self,sequence, pos_or_neg):\n",
        "        mapping = {'A': 0, 'R': 1, 'N': 2, 'D': 3, 'C': 4, 'E': 5, 'Q': 6, 'G': 7, 'H': 8, 'I': 9, 'L': 10, 'K': 11,\n",
        "                  'M': 12, 'F': 13, 'P': 14, 'S': 15, 'T': 16, 'W': 17, 'Y': 18, 'V': 19}\n",
        "        map=np.zeros((9, 20))\n",
        "        for i, seq in enumerate(sequence):\n",
        "            map[i,mapping[seq]]+=1\n",
        "        map = map.flatten()\n",
        "        return np.concatenate([map, np.array([pos_or_neg])])\n",
        "\n",
        "\n",
        "    def Read_Data(self,filename, pos_or_neg):\n",
        "        file = open(filename, 'r')\n",
        "        lines=file.readlines()\n",
        "        DATA = np.zeros((len(lines), 181))\n",
        "        for i, line in enumerate(lines):\n",
        "            input = self.data_to_input(line.replace('\\n', ''), pos_or_neg)\n",
        "            DATA[i] = input\n",
        "        return DATA\n",
        "\n",
        "\n",
        "    def bootstrap(self,DATA,size,NUMBER_OF_BATCHS):\n",
        "\n",
        "        new_DATA=np.zeros((size,181))\n",
        "        N=DATA.shape[0]\n",
        "        batch_size=N//NUMBER_OF_BATCHS\n",
        "        for i in range(NUMBER_OF_BATCHS):\n",
        "\n",
        "            random = np.random.randint(batch_size*i,batch_size*(i+1), size=size//NUMBER_OF_BATCHS)\n",
        "            new_DATA[((size//NUMBER_OF_BATCHS)*i):(size//NUMBER_OF_BATCHS)*(i+1), :] = DATA[random, :]\n",
        "        return new_DATA\n",
        "\n",
        "\n",
        "    def DATA_pre_pros(self,filename_pos,filename_neg):\n",
        "\n",
        "        neg_data=self.Read_Data(filename_neg, 0)\n",
        "        pos_data=self.Read_Data(filename_pos, 1)\n",
        "        \n",
        "        neg_data_train = neg_data[:int(len(neg_data)*0.9)]\n",
        "        neg_data_test = neg_data[int(len(neg_data)*0.9):]\n",
        "        pos_data_train = pos_data[:int(len(pos_data)*0.9)]\n",
        "        pos_data_test = pos_data[int(len(pos_data)*0.9):]\n",
        "        pos_data_train = self.bootstrap(pos_data_train, int(BOOTSTRAP_SIZE*0.9), NUMBER_OF_BATCHS)\n",
        "        pos_data_test = self.bootstrap(pos_data_test, int(BOOTSTRAP_SIZE*0.1), NUMBER_OF_BATCHS)\n",
        "\n",
        "        final_data_train = np.concatenate([neg_data_train, pos_data_train])\n",
        "        np.random.shuffle(final_data_train)\n",
        "\n",
        "        final_data_test = np.concatenate([neg_data_test, pos_data_test])\n",
        "        np.random.shuffle(final_data_test)\n",
        "\n",
        "        return final_data_train, final_data_test\n",
        "\n",
        "\n",
        "\n",
        "    def shuffle_data(self,data_Xy):\n",
        "        np.random.shuffle(data_Xy)\n",
        "        return data_Xy[:,:180],data_Xy[:,-1]\n",
        "\n",
        "\n",
        "    def spike_seq(self,filename):\n",
        "\n",
        "        mapping = {'A': 0, 'R': 1, 'N': 2, 'D': 3, 'C': 4, 'E': 5, 'Q': 6, 'G': 7, 'H': 8, 'I': 9, 'L': 10, 'K': 11,\n",
        "                  'M': 12, 'F': 13, 'P': 14, 'S': 15, 'T': 16, 'W': 17, 'Y': 18, 'V': 19}\n",
        "\n",
        "\n",
        "        with open(filename) as f:\n",
        "            lines = f.readlines()[0]\n",
        "            print(lines)\n",
        "            predeict=list()\n",
        "\n",
        "            if len(lines) == 9:\n",
        "                map = np.zeros((9, 20))\n",
        "                for i, seq in enumerate(lines):\n",
        "                    map[i, mapping[seq]] += 1\n",
        "                map = map.flatten()\n",
        "                predeict.append(map)\n",
        "            else:\n",
        "                for i in range(len(lines)-9):\n",
        "                    map = np.zeros((9, 20))\n",
        "                    for i, seq in enumerate(lines[i:i+9]):\n",
        "                        map[i, mapping[seq]] += 1\n",
        "                    map = map.flatten()\n",
        "                    predeict.append(map)\n",
        "            \n",
        "            return np.array(predeict)\n",
        "\n",
        "\n"
      ],
      "execution_count": 420,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HutCXePsE9KO"
      },
      "source": [
        "INPUT_1=20\n",
        "INPUT_2=10\n",
        "INPUT_3=10\n",
        "P_DROPOUT=0.4\n",
        "P_DROPOUT2=0.15\n",
        "\n",
        "class NetWork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_fc = nn.Linear(input_dim, INPUT_1)\n",
        "        \n",
        "        self.hidden_1_fc = nn.Linear(INPUT_1, INPUT_2)\n",
        "        \n",
        "        self.hidden_2_fc = nn.Linear(INPUT_2, INPUT_3)\n",
        "        \n",
        "        self.output_fc = nn.Linear(INPUT_3, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(P_DROPOUT)\n",
        "        self.dropout2 = nn.Dropout(P_DROPOUT2) \n",
        "        self.batch_norm_1 = nn.BatchNorm1d(INPUT_1)\n",
        "\n",
        "        self.batch_norm_2 = nn.BatchNorm1d(INPUT_2)\n",
        "\n",
        "        self.batch_norm_3 = nn.BatchNorm1d(INPUT_3)\n",
        "\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "   \n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        x = x.view(batch_size, -1)\n",
        "\n",
        "        h_1 = F.relu(self.input_fc(x))\n",
        "       \n",
        "        h_1=self.batch_norm_1(h_1)\n",
        "\n",
        "        h_1=self.dropout(h_1)\n",
        "\n",
        "        h_2 = F.relu(self.hidden_1_fc(h_1))\n",
        "\n",
        "        h_2=self.batch_norm_2(h_2)\n",
        "\n",
        "        h_2=self.dropout(h_2)\n",
        "\n",
        "        h_3 = F.relu(self.hidden_2_fc(h_2))\n",
        "\n",
        "        h_3=self.batch_norm_3(h_3)\n",
        "\n",
        "        h_3=self.dropout2(h_3)\n",
        "\n",
        "        y_pred = self.output_fc(h_3)\n",
        "\n",
        "       \n",
        "        \n",
        "        return y_pred, h_2\n"
      ],
      "execution_count": 437,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1jysnYBFurA"
      },
      "source": [
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def calculate_accuracy(y_pred, y):\n",
        "    top_pred = y_pred.argmax(1, keepdim = True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc\n",
        "\n",
        "\n",
        "def train(model, iterator_x, iterator_y, optimizer, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i, x in enumerate(iterator_x):\n",
        "        x = x.to(device)\n",
        "        y = iterator_y[i].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred, _ = model(x)\n",
        "        \n",
        "        loss = criterion(y_pred, y)\n",
        "\n",
        "        acc = calculate_accuracy(y_pred, y)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator_x), epoch_acc / len(iterator_x)\n",
        "\n",
        "\n",
        "def evaluate(model, iterator_x, iterator_y, criterion, device):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for i, x in enumerate(iterator_x):\n",
        "        x = x.to(device)\n",
        "        y = iterator_y[i].to(device)\n",
        "\n",
        "        y_pred, _ = model(x)\n",
        "        \n",
        "        loss = criterion(y_pred, y)\n",
        "\n",
        "        acc = calculate_accuracy(y_pred, y)\n",
        "\n",
        " \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator_x), epoch_acc / len(iterator_x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 309,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNHufHg2Gyz5"
      },
      "source": [
        "filename_pos='/content/ex1_DL/resorces/pos_A0201.txt'\n",
        "filename_neg='/content/ex1_DL/resorces/neg_A0201.txt'\n",
        "\n",
        "my_ds = DataProccesing()\n",
        "train_set, test_set=my_ds.DATA_pre_pros(filename_pos,filename_neg)\n",
        "train_dataloader=data.DataLoader(dataset=train_set, batch_size=64,shuffle=True)\n",
        "test_dataloader= data.DataLoader(dataset=test_set, batch_size=64,shuffle=True )\n",
        "print(np.sum(train_set[:, -1]))\n",
        "\n",
        "# LEARNNING_RATE=0.00015\n",
        "\n",
        "def main():\n",
        "    model = NetWork(INPUT_DIM, 2)\n",
        "    print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "    optimizer = optim.Adam(model.parameters(),lr=LEARNNING_RATE)\n",
        "\n",
        "    # weights = [np.sum(train_set[:, -1])/train_set.shape[0], 1-np.sum(train_set[:, -1])/train_set.shape[0]] #as class distribution\n",
        "    # class_weights = torch.FloatTensor(weights)\n",
        "    # criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "    criterion = criterion.to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    EPOCHS = 50\n",
        "\n",
        "    best_valid_loss = float('inf')\n",
        "    train_per_ep=[]\n",
        "    test_per_ep=[]\n",
        "    test_acc = 0\n",
        "    for epoch in range(EPOCHS):\n",
        "\n",
        "\n",
        "        train_x,train_y=my_ds.shuffle_data(train_set)\n",
        "        train_iterator_x = torch.from_numpy(train_x.astype('float32')).split(64)\n",
        "        train_iterator_y = torch.from_numpy(train_y.astype('int64')).split(64)\n",
        "\n",
        "        test_x,test_y=my_ds.shuffle_data(test_set)\n",
        "        test_iterator_x = torch.from_numpy(test_x.astype('float32')).split(64)\n",
        "        test_iterator_y = torch.from_numpy(test_y.astype('int64')).split(64)\n",
        "\n",
        "        train_loss, train_acc = train(model, train_iterator_x, train_iterator_y, optimizer, criterion, device)\n",
        "\n",
        "        test_loss, test_acc = evaluate(model, test_iterator_x, test_iterator_y,criterion, device)\n",
        "        train_per_ep.append(train_loss)\n",
        "        test_per_ep.append(test_loss)\n",
        "        \n",
        "        print(f'Epoch: {epoch + 1:02}')\n",
        "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
        "        print(f'Epoch: {epoch + 1:02}')\n",
        "        print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc * 100:.2f}%')\n",
        "\n",
        "    train_per_ep=np.array(train_per_ep)\n",
        "    test_per_ep=np.array(test_per_ep)\n",
        "    epocs=np.arange(1,EPOCHS+1)\n",
        "    plt.figure()\n",
        "    plt.plot(epocs,train_per_ep)\n",
        "    plt.plot(epocs,test_per_ep)\n",
        "    plt.legend(['train loss','test loss'])\n",
        "    plt.show()\n",
        "    return test_acc, np.mean(np.abs(np.array(train_per_ep) - np.array(test_per_ep)))"
      ],
      "execution_count": 404,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heAumw8VTJUC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkTUKuGfTuIE"
      },
      "source": [
        "learning_rate = np.linspace(0.0005, 0.01, num=10)\n",
        "input_1 = [20, 30, 40]\n",
        "input_2 = [10, 20, 30]\n",
        "input_3 = [5, 10, 15]\n",
        "p = [0.2, 0.35, 0.5] \n",
        "acc = list()\n",
        "overfit=list()\n",
        "\n",
        "all=np.load('/content/drive/MyDrive/Colab Notebooks/opt.npy',allow_pickle=True)\n",
        "i=0\n",
        "for rate in learning_rate:\n",
        "  for input_1_ in input_1:\n",
        "    for input_2_ in input_2:\n",
        "      for input_3_ in input_3:\n",
        "        for p_ in p:\n",
        "            LEARNNING_RATE = rate\n",
        "            INPUT_1 = input_1_\n",
        "            INPUT_2 = input_2_\n",
        "            INPUT_3 = input_3_\n",
        "            P_DROPOUT = p_ \n",
        "\n",
        "            if any((np.array([INPUT_1,INPUT_2,INPUT_3,P_DROPOUT,LEARNNING_RATE])==all[:,0:-2]).all(1)):\n",
        "              print(i)\n",
        "              i+=1\n",
        "              continue\n",
        "            else:  \n",
        "              ac,of = main()\n",
        "              acc.append(ac)\n",
        "              overfit.append(of)\n",
        "              params=np.array([INPUT_1,INPUT_2,INPUT_3,P_DROPOUT,LEARNNING_RATE, ac, of])\n",
        "              all=np.vstack([all, params])\n",
        "              np.save('/content/drive/MyDrive/Colab Notebooks/opt.npy',all)\n",
        "          \n",
        "\n",
        "        \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZWo5iKwKtfD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "633a2f41-810a-414a-e4c1-ff70cea720e3"
      },
      "source": [
        "filename_pos='/content/ex1_DL/resorces/pos_A0201.txt'\n",
        "filename_neg='/content/ex1_DL/resorces/neg_A0201.txt'\n",
        "\n",
        "my_ds = DataProccesing()\n",
        "train_set, test_set=my_ds.DATA_pre_pros(filename_pos,filename_neg)\n",
        "train_dataloader=data.DataLoader(dataset=train_set, batch_size=64,shuffle=True)\n",
        "test_dataloader= data.DataLoader(dataset=test_set, batch_size=64,shuffle=True )\n",
        "print(np.sum(train_set[:, -1]))\n",
        "\n",
        "LEARNNING_RATE=0.005\n",
        "\n",
        "\n",
        "model = NetWork(INPUT_DIM, 2)\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "optimizer = optim.Adam(model.parameters(),lr=LEARNNING_RATE)\n",
        "\n",
        "# weights = [np.sum(train_set[:, -1])/train_set.shape[0], 1-np.sum(train_set[:, -1])/train_set.shape[0]] #as class distribution\n",
        "# class_weights = torch.FloatTensor(weights)\n",
        "# criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "EPOCHS = 20\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "train_per_ep=[]\n",
        "test_per_ep=[]\n",
        "test_acc = 0\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "\n",
        "    train_x,train_y=my_ds.shuffle_data(train_set)\n",
        "    train_iterator_x = torch.from_numpy(train_x.astype('float32')).split(64)\n",
        "    train_iterator_y = torch.from_numpy(train_y.astype('int64')).split(64)\n",
        "\n",
        "    test_x,test_y=my_ds.shuffle_data(test_set)\n",
        "    test_iterator_x = torch.from_numpy(test_x.astype('float32')).split(64)\n",
        "    test_iterator_y = torch.from_numpy(test_y.astype('int64')).split(64)\n",
        "\n",
        "    train_loss, train_acc = train(model, train_iterator_x, train_iterator_y, optimizer, criterion, device)\n",
        "\n",
        "    test_loss, test_acc = evaluate(model, test_iterator_x, test_iterator_y,criterion, device)\n",
        "    train_per_ep.append(train_loss)\n",
        "    test_per_ep.append(test_loss)\n",
        "    \n",
        "    print(f'Epoch: {epoch + 1:02}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
        "    print(f'Epoch: {epoch + 1:02}')\n",
        "    print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc * 100:.2f}%')\n",
        "\n",
        "train_per_ep=np.array(train_per_ep)\n",
        "test_per_ep=np.array(test_per_ep)\n",
        "epocs=np.arange(1,EPOCHS+1)\n",
        "print(np.mean(np.abs(np.array(train_per_ep) - np.array(test_per_ep))))\n",
        "plt.figure()\n",
        "plt.plot(epocs,train_per_ep)\n",
        "plt.plot(epocs,test_per_ep)\n",
        "plt.legend(['train loss','test loss'])\n",
        "plt.show()"
      ],
      "execution_count": 435,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11600.0\n",
            "The model has 4,042 trainable parameters\n",
            "Epoch: 01\n",
            "\tTrain Loss: 0.337 | Train Acc: 85.07%\n",
            "Epoch: 01\n",
            "\tTest Loss: 0.253 | Test Acc: 89.09%\n",
            "Epoch: 02\n",
            "\tTrain Loss: 0.272 | Train Acc: 88.51%\n",
            "Epoch: 02\n",
            "\tTest Loss: 0.234 | Test Acc: 90.21%\n",
            "Epoch: 03\n",
            "\tTrain Loss: 0.261 | Train Acc: 88.83%\n",
            "Epoch: 03\n",
            "\tTest Loss: 0.234 | Test Acc: 90.12%\n",
            "Epoch: 04\n",
            "\tTrain Loss: 0.256 | Train Acc: 89.33%\n",
            "Epoch: 04\n",
            "\tTest Loss: 0.240 | Test Acc: 89.87%\n",
            "Epoch: 05\n",
            "\tTrain Loss: 0.248 | Train Acc: 89.61%\n",
            "Epoch: 05\n",
            "\tTest Loss: 0.227 | Test Acc: 90.20%\n",
            "Epoch: 06\n",
            "\tTrain Loss: 0.241 | Train Acc: 89.95%\n",
            "Epoch: 06\n",
            "\tTest Loss: 0.260 | Test Acc: 90.06%\n",
            "Epoch: 07\n",
            "\tTrain Loss: 0.240 | Train Acc: 90.05%\n",
            "Epoch: 07\n",
            "\tTest Loss: 0.245 | Test Acc: 90.39%\n",
            "Epoch: 08\n",
            "\tTrain Loss: 0.241 | Train Acc: 90.16%\n",
            "Epoch: 08\n",
            "\tTest Loss: 0.231 | Test Acc: 89.82%\n",
            "Epoch: 09\n",
            "\tTrain Loss: 0.230 | Train Acc: 90.69%\n",
            "Epoch: 09\n",
            "\tTest Loss: 0.239 | Test Acc: 89.84%\n",
            "Epoch: 10\n",
            "\tTrain Loss: 0.232 | Train Acc: 90.58%\n",
            "Epoch: 10\n",
            "\tTest Loss: 0.259 | Test Acc: 90.35%\n",
            "Epoch: 11\n",
            "\tTrain Loss: 0.228 | Train Acc: 90.67%\n",
            "Epoch: 11\n",
            "\tTest Loss: 0.239 | Test Acc: 90.19%\n",
            "Epoch: 12\n",
            "\tTrain Loss: 0.226 | Train Acc: 90.90%\n",
            "Epoch: 12\n",
            "\tTest Loss: 0.243 | Test Acc: 89.72%\n",
            "Epoch: 13\n",
            "\tTrain Loss: 0.219 | Train Acc: 91.31%\n",
            "Epoch: 13\n",
            "\tTest Loss: 0.244 | Test Acc: 90.51%\n",
            "Epoch: 14\n",
            "\tTrain Loss: 0.219 | Train Acc: 91.22%\n",
            "Epoch: 14\n",
            "\tTest Loss: 0.245 | Test Acc: 90.53%\n",
            "Epoch: 15\n",
            "\tTrain Loss: 0.214 | Train Acc: 91.52%\n",
            "Epoch: 15\n",
            "\tTest Loss: 0.223 | Test Acc: 90.84%\n",
            "Epoch: 16\n",
            "\tTrain Loss: 0.213 | Train Acc: 91.52%\n",
            "Epoch: 16\n",
            "\tTest Loss: 0.226 | Test Acc: 90.78%\n",
            "Epoch: 17\n",
            "\tTrain Loss: 0.212 | Train Acc: 91.70%\n",
            "Epoch: 17\n",
            "\tTest Loss: 0.236 | Test Acc: 90.26%\n",
            "Epoch: 18\n",
            "\tTrain Loss: 0.212 | Train Acc: 91.64%\n",
            "Epoch: 18\n",
            "\tTest Loss: 0.239 | Test Acc: 90.66%\n",
            "Epoch: 19\n",
            "\tTrain Loss: 0.212 | Train Acc: 91.59%\n",
            "Epoch: 19\n",
            "\tTest Loss: 0.255 | Test Acc: 90.38%\n",
            "Epoch: 20\n",
            "\tTrain Loss: 0.208 | Train Acc: 91.88%\n",
            "Epoch: 20\n",
            "\tTest Loss: 0.261 | Test Acc: 88.97%\n",
            "0.025375527957698034\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfftOmlOTnCL",
        "outputId": "f04b9918-4a4a-4b9f-aaa9-77d83a00220a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "seq=spike_seq('/content/ex1_DL/resorces/spike_acid.txt')\n",
        "print(seq)\n",
        "\n",
        "seq = torch.from_numpy(seq.astype('float32'))\n",
        "seq = seq.to(device)\n",
        "y_pred, _ = model(seq)\n",
        "z = y_pred\n",
        "my_softmax = nn.Softmax(dim=1)\n",
        "z = my_softmax(z)\n",
        "print(z)"
      ],
      "execution_count": 397,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLNEEIARV\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
            "tensor([[0.1953, 0.8047]], grad_fn=<SoftmaxBackward>)\n"
          ]
        }
      ]
    }
  ]
}